{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Karl Pearson’s correlation\n",
    "\n",
    "##  variables must have a Gaussian distribution and a linear relationship\n",
    "\n",
    "## Covariance\n",
    "\n",
    "### cov(x,y) = sum((x-mean(x))*(y-mean(y)))/(n-1)\n",
    "\n",
    "## A problem with covariance as a statistical tool alone is that it is challenging to interpret. This leads us to the Pearson’s correlation coefficient next.\n",
    "\n",
    "## The Pearson’s correlation coefficient is calculated as the covariance of the two variables divided by the product of the standard deviation of each data sample. It is the normalization of the covariance between the two variables to give an interpretable score.\n",
    "\n",
    "### Pearson’s correlation coefficient = covariance(x,y)/(stdv(x)*stdv(y))\n",
    "\n",
    "## The use of mean and standard deviation in the calculation suggests the need for the two data samples to have a Gaussian or Gaussian-like distribution.\n",
    "\n",
    "# Spearman’s Correlation\n",
    "\n",
    "## Two variables may be related by a nonlinear relationship, such that the relationship is stronger or weaker across the distribution of the variables\n",
    "\n",
    "## the two variables being considered may have a non-Gaussian distribution.\n",
    "\n",
    "## This test of relationship can also be used if there is a linear relationship between the variables, but will have slightly less power (e.g. may result in lower coefficient scores).\n",
    "\n",
    "## Instead of calculating the coefficient using covariance and standard deviations on the samples themselves, these statistics are calculated from the relative rank of values on each sample. This is a common approach used in non-parametric statistics, e.g. statistical methods where we do not assume a distribution of the data such as Gaussian.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 2 µs, total: 12 µs\n",
      "Wall time: 16.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def findNumber(arr_1, arr_2):\n",
    "    History_Scores = list(arr_1)\n",
    "    Physics_Scores = list(arr_2)\n",
    "    avg_history_score = float(sum(History_Scores))/len(History_Scores)\n",
    "    avg_physics_score = float(sum(Physics_Scores))/len(Physics_Scores)\n",
    "    difference_history_score = map(lambda x: x-avg_history_score,History_Scores)\n",
    "    difference_physics_score = map(lambda x: x-avg_physics_score,Physics_Scores)\n",
    "    product = map(lambda x,y:x*y,(difference_history_score),(difference_physics_score))\n",
    "    coeff = sum(product)\n",
    "    stdv__history_score = (sum([i**2 for i in difference_history_score]))**0.5\n",
    "    stdv__physics_score = (sum([i**2 for i in difference_physics_score]))**0.5\n",
    "    score = coeff/(stdv__history_score*stdv__physics_score)\n",
    "    print(\"Karl Pearson’s coefficient {score:.3f}\".format(score=score))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson correlation coefficient and p-value for testing non-correlation.\n",
    "\n",
    "    The Pearson correlation coefficient [1]_ measures the linear relationship\n",
    "    between two datasets.  The calculation of the p-value relies on the\n",
    "    assumption that each dataset is normally distributed.  (See Kowalski [3]_\n",
    "    for a discussion of the effects of non-normality of the input on the\n",
    "    distribution of the correlation coefficient.)  Like other correlation\n",
    "    coefficients, this one varies between -1 and +1 with 0 implying no\n",
    "    correlation. Correlations of -1 or +1 imply an exact linear relationship.\n",
    "    Positive correlations imply that as x increases, so does y. Negative\n",
    "    correlations imply that as x increases, y decreases.\n",
    "\n",
    "    The p-value roughly indicates the probability of an uncorrelated system\n",
    "    producing datasets that have a Pearson correlation at least as extreme\n",
    "    as the one computed from these datasets.\n",
    "    \n",
    "    \n",
    "    r = \\frac{\\sum (x - m_x) (y - m_y)}\n",
    "                 {\\sqrt{\\sum (x - m_x)^2 \\sum (y - m_y)^2}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.14499815458068518, 0.6894014481166955)\n",
      "CPU times: user 570 µs, sys: 0 ns, total: 570 µs\n",
      "Wall time: 500 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import scipy.stats as s\n",
    "History_Scores = [10,  25,  17,  11,  13,  17,  20,  13,  9,   15]\n",
    "Physics_Scores = [15,  12,  8,   8,   7,   7,   7,   6,   5,   3]\n",
    "print(s.pearsonr(History_Scores,Physics_Scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give History Score list here[10,  25,  17,  11,  13,  17,  20,  13,  9,   15]\n",
      "Give Physics Score list here[15,  12,  8,   8,   7,   7,   7,   6,   5,   3]\n",
      "Karl Pearson’s coefficient 0.145\n"
     ]
    }
   ],
   "source": [
    "History_Scores = list(input(\"Give History Score list here\"))\n",
    "Physics_Scores = list(input(\"Give Physics Score list here\"))\n",
    "avg_history_score = float(sum(History_Scores))/len(History_Scores)\n",
    "avg_physics_score = float(sum(Physics_Scores))/len(Physics_Scores)\n",
    "difference_history_score = map(lambda x: x-avg_history_score,History_Scores)\n",
    "difference_physics_score = map(lambda x: x-avg_physics_score,Physics_Scores)\n",
    "product = map(lambda x,y:x*y,(difference_history_score),(difference_physics_score))\n",
    "coeff = sum(product)\n",
    "stdv__history_score = (sum([i**2 for i in difference_history_score]))**0.5\n",
    "stdv__physics_score = (sum([i**2 for i in difference_physics_score]))**0.5\n",
    "score = coeff/(stdv__history_score*stdv__physics_score)\n",
    "print(\"Karl Pearson’s coefficient {score:.3f}\".format(score=score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.807027216905996, 1.708185943772348e-05)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "def findNumber(arr_1, arr_2):\n",
    "    History_Scores = list(arr_1)\n",
    "    Physics_Scores = list(arr_2)\n",
    "    if len(History_Scores)==len(Physics_Scores) and (len(History_Scores) >2 and len(Physics_Scores) ):\n",
    "        avg_history_score = float(sum(History_Scores))/len(History_Scores)\n",
    "        avg_physics_score = float(sum(Physics_Scores))/len(Physics_Scores)\n",
    "        difference_history_score = list(map(lambda x: x-avg_history_score,History_Scores))\n",
    "        difference_physics_score = list(map(lambda x: x-avg_physics_score,Physics_Scores))\n",
    "        product = map(lambda x,y:x*y,(difference_history_score),(difference_physics_score))\n",
    "        coeff = sum(product)\n",
    "        stdv__history_score = (sum([i**2 for i in difference_history_score]))**0.5\n",
    "        stdv__physics_score = (sum([i**2 for i in difference_physics_score]))**0.5\n",
    "        if stdv__history_score>0 and stdv__physics_score>0:\n",
    "            score = coeff/(stdv__history_score*stdv__physics_score)\n",
    "            print(round(score,3))\n",
    "            return score\n",
    "        else:\n",
    "            raise ValueError(\"Invalid data\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid Data\")\n",
    "if __name__ == '__main__' :\n",
    "    arr_1 = map(int,input().rstrip().split())\n",
    "    arr_2 = map(int,input().rstrip().split())\n",
    "    findNumber(arr_1, arr_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "lines=[]\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        lines.append(list(map(int,input().rstrip().split())))\n",
    "    except:\n",
    "        break\n",
    "        \n",
    "k = lines[0][0]\n",
    "m = lines[0][1]\n",
    "        \n",
    "if 1<=m<=1000 and 1<=k<=7:\n",
    "    sqlist=[]\n",
    "    for li in lines:\n",
    "        if li[0]>7:\n",
    "            exit()\n",
    "        del li[0]\n",
    "        for lij in li:\n",
    "            if 1<=lij<=10**9:\n",
    "                pass\n",
    "            else:\n",
    "                exit()\n",
    "    for i in lines:\n",
    "        print(i)\n",
    "        sqlist.append(list(map(lambda X:X**2,i)))\n",
    "    print(sqlist)\n",
    "    for k in list(product(*sqlist)):\n",
    "        remainder=sum(list(k))%m\n",
    "        maxremainnder= remainder if remainder>maxremainnder else maxremainnder\n",
    "    print(maxremainnder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial regression is a special case of linear regression. With the main idea of how do you select your features. Looking at the multivariate regression with 2 variables: x1 and x2. Linear regression will look like this: y = a1 * x1 + a2 * x2.\n",
    "\n",
    "# Now you want to have a polynomial regression (let's make 2 degree polynomial). We will create a few additional features: x1*x2, x1^2 and x2^2. So we will get your 'linear regression':\n",
    "\n",
    "# y = a1 * x1 + a2 * x2 + a3 * x1*x2 + a4 * x1^2 + a5 * x2^2\n",
    "\n",
    "# This nicely shows an important concept curse of dimensionality, because the number of new features grows much faster than linearly with the growth of degree of polynomial.\n",
    "\n",
    "# In case you are using a multivariate regression and not just a univariate regression, do not forget the cross terms. For instance if you have two variables x1 and x2, and you want polynomials up to power 2, you should use y=a1x1+a2x2+a3x21+a4x22+a5x1x2 where the last term (a5x1x2) is the one I am talking about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mn = input()\n",
    "mn = mn.strip().split(' ')\n",
    "\n",
    "m = int(mn[0])\n",
    "n = int(mn[1])\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(n):\n",
    "    x = input()\n",
    "    x = x.strip().split(' ')\n",
    "    x = [float(a) for a in x]\n",
    "    X.append(x[0:m])\n",
    "    Y.append(x[m:])\n",
    "\n",
    "q = input()\n",
    "q = int(q.strip())\n",
    "\n",
    "X_test = []\n",
    "for i in range(q):\n",
    "    x_test = input()\n",
    "    x_test = x_test.strip().split(' ')\n",
    "    x_test = [float(a) for a in x_test]\n",
    "    X_test.append(x_test)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "poly.fit(np.array(X))\n",
    "\n",
    "regression = LinearRegression()\n",
    "regression.fit(poly.transform(np.array(X)), Y)\n",
    "\n",
    "Y_test = regression.predict(poly.transform(np.array(X_test)))\n",
    "for y_test in Y_test:\n",
    "    print(round(y_test[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_c_c(x, y, n):\n",
    "    sum_xi_yi = sum([x[i] * y[i] for i in range(n)])\n",
    "    prod = sum(x) * sum(y)\n",
    "    s_x = (n * sum([x[i] * x[i] for i in range(n)])) - sum(x) ** 2\n",
    "    s_y = (n * sum([y[i] * y[i] for i in range(n)])) - sum(y) ** 2\n",
    "    denom = (s_x * s_y) ** 0.5\n",
    "    nume = (n * sum_xi_yi) - prod\n",
    "    return round((nume / denom), 2)\n",
    "\n",
    "\n",
    "number_of_rows = int(input().strip())\n",
    "math = []\n",
    "phy = []\n",
    "che = []\n",
    "for _ in range(number_of_rows):\n",
    "    row_i = list(map(float, input().strip().split()))\n",
    "    math.append(row_i[0])\n",
    "    phy.append(row_i[1])\n",
    "    che.append(row_i[2])\n",
    "\n",
    "print(p_c_c(math, phy, number_of_rows))\n",
    "print(p_c_c(phy, che, number_of_rows))\n",
    "print(p_c_c(che, math, number_of_rows))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "col_row_count=list(map(int,input().strip().split()))\n",
    "col_count=col_row_count[0]\n",
    "row_count=col_row_count[1]\n",
    "train=[]\n",
    "target=[]\n",
    "for i in range(row_count):\n",
    "    row_i=list(map(float,input().strip().split()))\n",
    "    train.append(row_i[:col_count])\n",
    "    target.append(row_i[-1])\n",
    "\n",
    "test_count=int(input().strip())\n",
    "\n",
    "test=[]\n",
    "\n",
    "for i in range(test_count):\n",
    "    row_i=list(map(float,input().strip().split()))\n",
    "    test.append(row_i[:col_count])\n",
    "\n",
    "lm=LinearRegression()\n",
    "lm.fit(train,target)\n",
    "print(\"\\n\".join(list(map(str,lm.predict(test)))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
